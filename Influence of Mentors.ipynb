{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyximport\n",
    "import numpy as np\n",
    "pyximport.install(setup_args={\"include_dirs\": np.get_include()},\n",
    "                  reload_support=True)\n",
    "from algorithms.knn_neighborhood import UserKNN\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = [iid for iid, _ in user_ratings[:n]]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/ml-100k/u.data\", sep=\"\\t\")\n",
    "data_df.columns = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "data_df.drop(columns=[\"timestamp\"], axis=1, inplace=True)\n",
    "data_df[\"user_id\"] = data_df[\"user_id\"].map({b: a for a, b in enumerate(data_df[\"user_id\"].unique())})\n",
    "data_df[\"item_id\"] = data_df[\"item_id\"].map({b: a for a, b in enumerate(data_df[\"item_id\"].unique())})\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "dataset = Dataset.load_from_df(data_df, reader=reader)\n",
    "raw_trainset = [(ruid, riid, r, None) for ruid, riid, r in train_df.to_records(index=False)]\n",
    "raw_testset = [(ruid, riid, r, None) for ruid, riid, r in test_df.to_records(index=False)]\n",
    "trainset = Dataset.construct_trainset(dataset, raw_trainset)\n",
    "testset = Dataset.construct_testset(dataset, raw_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = UserKNN().compute_similarities(trainset, min_support=1)\n",
    "pop = UserKNN().compute_popularities(trainset)\n",
    "gain = UserKNN().compute_gain(trainset)\n",
    "\n",
    "model = UserKNN(k=30, precomputed_sim=sim)\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "mae = accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "topn = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = np.zeros(train_df[\"user_id\"].nunique())\n",
    "influence = np.zeros(train_df[\"user_id\"].nunique())\n",
    "s = dt.now()\n",
    "i = 1\n",
    "for ruid in train_df[\"user_id\"].unique():\n",
    "    train_without_u_df = train_df[train_df[\"user_id\"] != ruid]\n",
    "    raw_trainset = [(ruid, riid, r, None) for ruid, riid, r in train_without_u_df.to_records(index=False)]\n",
    "    trainset_without_u = Dataset.construct_trainset(dataset, raw_trainset)\n",
    "    \n",
    "    model_without_u = UserKNN(k=30, precomputed_sim=sim)\n",
    "    model_without_u.fit(trainset_without_u)\n",
    "    predictions_without_u = model_without_u.test(testset)\n",
    "    mae_without_u = accuracy.mae(predictions_without_u, verbose=False)\n",
    "    maes[ruid] = mae_without_u\n",
    "    \n",
    "    topn_without_u = get_top_n(predictions_without_u, n=10)\n",
    "    jdists = []\n",
    "    for uid in topn_without_u.keys():\n",
    "        jdist = 1 - len(set(topn_without_u[uid]).intersection(topn[uid])) / len(set(topn_without_u[uid]).union(topn[uid]))\n",
    "        jdists.append(jdist)\n",
    "    influence[ruid] = np.mean(jdists)\n",
    "    \n",
    "    print(\"[%f%% Done] Time elapsed %s, Influence %f, MAE Diff: %f\" % (100 * i / train_df[\"user_id\"].nunique(), dt.now() - s, influence[ruid], maes[ruid] - mae))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
